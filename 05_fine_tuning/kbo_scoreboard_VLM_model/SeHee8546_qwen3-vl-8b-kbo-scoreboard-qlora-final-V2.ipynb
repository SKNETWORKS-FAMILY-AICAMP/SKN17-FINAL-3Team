{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfce2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.57.0 at https://files.pythonhosted.org/packages/e5/2b/4d2708ac1ff5cd708b6548f4c5812d0ae40d1c28591c4c1c762b6dbdef2d/transformers-4.57.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.9.0))\n",
      "Reason for being yanked: Error in the setup causing installation issues\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate pynvml huggingface_hub hf_transfer \"transformers==4.57.0\" \n",
    "!pip install -q trl peft scikit-learn bitsandbytes pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] device = cuda\n",
      "[INFO] 유틸/설정 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    Qwen3VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 기본 설정\n",
    "MODEL_ID = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "DATA_PATH = \"tuning_data_final8_image_change.jsonl\"\n",
    "OUTPUT_DIR = \"qwen3-vl-8b-kbo-scoreboard-qlora\"\n",
    "SEED = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device = {device}\")\n",
    "\n",
    "# 유틸 함수\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_raw_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    data: List[Dict[str, Any]] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "set_seed(SEED)\n",
    "print(\"유틸/설정 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984168ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train: 263, Eval: 32\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 & Qwen3-VL 포맷 변환\n",
    "raw_data = load_raw_jsonl(DATA_PATH)\n",
    "\n",
    "# 데이터셋 분할 로직\n",
    "def train_eval_test_split(data, train_ratio=0.8, eval_ratio=0.1, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    data_shuffled = list(data)\n",
    "    rng.shuffle(data_shuffled)\n",
    "    n_total = len(data_shuffled)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_eval = int(n_total * eval_ratio)\n",
    "    return data_shuffled[:n_train], data_shuffled[n_train:n_train+n_eval], data_shuffled[n_train+n_eval:]\n",
    "\n",
    "train_dataset, eval_dataset, test_dataset = train_eval_test_split(raw_data, seed=SEED)\n",
    "print(f\"[INFO] Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedde09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compute_dtype = torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fa2ca147f14fc89b704d33730f73a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 모델 / 프로세서 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 4bit Qlora 양자화 Qwen3-VL 모델 / 프로세서 로드\n",
    "if torch.cuda.is_available():\n",
    "    major, minor = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        compute_dtype = torch.bfloat16\n",
    "    else:\n",
    "        compute_dtype = torch.float16\n",
    "else:\n",
    "    compute_dtype = torch.float32\n",
    "\n",
    "print(f\"compute_dtype = {compute_dtype}\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    dtype=compute_dtype,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\" \n",
    ")\n",
    "\n",
    "min_pixels = 256 * 28 * 28 # 기본값보다 높게\n",
    "max_pixels = 1920 * 1080\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    min_pixels=min_pixels, \n",
    "    max_pixels=max_pixels\n",
    ")\n",
    "\n",
    "# 패딩/캐시 설정\n",
    "if hasattr(model, \"config\"):\n",
    "    model.config.use_cache = False\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "if hasattr(model, \"enable_input_require_grads\"):\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "if hasattr(processor, \"tokenizer\"):\n",
    "    tokenizer = processor.tokenizer\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(\"모델 / 프로세서 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:1222: UserWarning: Model has `tie_word_embeddings=True` and a tied layer is part of the adapter, but `ensure_weight_tying` is not set to True. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. Check the discussion here: https://github.com/huggingface/peft/issues/2777\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SFTTrainer 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# LoRA 설정, 학습 설정, SFTTrainer 생성\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ], # 모든 리니어 레이어 타겟팅\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    modules_to_save=[\"embed_tokens\", \"lm_head\"], # 토큰 임베딩 학습 허용 (특수 포맷 적응력 향상)\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64,                 # 기존 16 -> 64: 시각적 디테일 학습을 위해 표현력 증대\n",
    "    lora_alpha=128,       # 기존 32 -> 128: alpha는 보통 rank의 2배 설정\n",
    "    lora_dropout=0.05,    # 0.1 -> 0.05: 데이터가 적으므로 너무 많이 끄지 않음\n",
    "    bias=\"none\",\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ], # 모든 리니어 레이어 타겟팅\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    modules_to_save=[\"embed_tokens\", \"lm_head\"], # 토큰 임베딩 학습 허용 (특수 포맷 적응력 향상)\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    \n",
    "    max_length=4096,  # FHD 이미지(우리 데이터 대부분의 크기)는 토큰 약 2000개 이상 차지.. 텍스트 포함 여유 있게 4096 설정\n",
    "    \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,      \n",
    "    \n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    \n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    bf16=True,\n",
    "    max_grad_norm=1.0,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    remove_unused_columns=False,\n",
    "    dataset_text_field=\"\", \n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=processor,\n",
    ")\n",
    "\n",
    "print(\"SFTTrainer 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aecc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파인튜닝 시작...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 59:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10.064700</td>\n",
       "      <td>5.006711</td>\n",
       "      <td>6.360070</td>\n",
       "      <td>548948.000000</td>\n",
       "      <td>0.343032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.411500</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>1067069.000000</td>\n",
       "      <td>0.997461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>1615905.000000</td>\n",
       "      <td>0.999281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>2134018.000000</td>\n",
       "      <td>0.999554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>2682972.000000</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>3201346.000000</td>\n",
       "      <td>0.999709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>3719357.000000</td>\n",
       "      <td>0.999727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>4268145.000000</td>\n",
       "      <td>0.999718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 완료\n",
      "어댑터 저장 완료: qwen3-vl-8b-kbo-scoreboard-qlora\n"
     ]
    }
   ],
   "source": [
    "print(\"파인튜닝 시작...\")\n",
    "train_result = trainer.train()\n",
    "print(\"학습 완료\")\n",
    "\n",
    "# 어댑터 저장\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "print(f\"어댑터 저장 완료: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8642961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0691245c2bb643e1bc9edf6cef5d0197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510a5a0d01724b948ca671d3e4dcf0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Hugging Face Hub 업로드 완료: SeHee8546/qwen3-vl-8b-kbo-scoreboard-qlora-final-V2\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "HF_REPO_ID = \"SeHee8546/qwen3-vl-8b-kbo-scoreboard-qlora-final-V2\"\n",
    "HF_TOKEN='<토큰값>'\n",
    "\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "api.create_repo(repo_id=HF_REPO_ID, exist_ok=True)\n",
    "\n",
    "api.upload_folder(\n",
    "    repo_id=HF_REPO_ID,\n",
    "    folder_path=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(f\"Hugging Face Hub 업로드 완료: {HF_REPO_ID}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
