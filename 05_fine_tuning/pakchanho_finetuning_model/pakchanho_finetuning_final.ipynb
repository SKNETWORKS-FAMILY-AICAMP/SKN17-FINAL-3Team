{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09ccdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"transformers>=4.45.0\" \"trl>=0.8.6\" \"peft>=0.12.0\" \"datasets>=2.20.0\" scikit-learn accelerate\n",
    "!pip install -q bert-score hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b2945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda / dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# 설정\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DATA_PATH = \"박찬호_파인튜닝데이터_최종.jsonl\"\n",
    "BASE_MODEL_NAME = \"kakaocorp/kanana-1.5-8b-instruct-2505\"\n",
    "OUTPUT_DIR = \"kanana_pakchanho_lora_v2\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16\n",
    "\n",
    "print(\"DEVICE:\", DEVICE, \"/ dtype:\", DTYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ccb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수: 1062\n",
      "예시 1개:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"경기: 2013_WBC_대한민국_네덜란드\\n당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"자, 정근우 선수가 지금 보이고 있는데요. 정근우 선수, 어, 투수에게도 오늘 바람이 영향이 있다면 타자들에게도 영향이 있지 않습니까?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"영향이 많습니다. 외야 플라이 볼이, 어, 뻗어가지 않기 때문에, 그래서, 어, 단타 위주로 가는 게, 오히려, 그걸 노리는 게 오히려 더 효율적일 것 같습니다.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "def load_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "raw_data = load_jsonl(DATA_PATH)\n",
    "print(f\"총 샘플 수: {len(raw_data)}\")\n",
    "print(\"예시 1개:\")\n",
    "print(json.dumps(raw_data[0], ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb7c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 849\n",
      "validation 106\n",
      "test 107\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "# 형식: {\"messages\": [ {role: system}, {role: user}, {role: assistant} ] }\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "\n",
    "# 80 / 10 / 10 split\n",
    "dataset_train_valid = dataset.train_test_split(test_size=0.2, seed=SEED)\n",
    "dataset_valid_test = dataset_train_valid[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "\n",
    "ds = DatasetDict(\n",
    "    {\n",
    "        \"train\": dataset_train_valid[\"train\"],\n",
    "        \"validation\": dataset_valid_test[\"train\"],\n",
    "        \"test\": dataset_valid_test[\"test\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    print(split, len(ds[split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fce382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e605ba1e84947a0859f2ac5fe7a3225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75c0ff2468d4b049148e96a445ae075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8907bb135741e1a9efc4f5b6962622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token: <|end_of_text|>  / eos_token: <|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 로드\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "# padding 토큰 설정\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token, \" / eos_token:\", tokenizer.eos_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74170d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFTConfig(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "activation_offloading=False,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "assistant_only_loss=False,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=True,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "chat_template_path=None,\n",
      "completion_only_loss=None,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset_kwargs=None,\n",
      "dataset_num_proc=None,\n",
      "dataset_text_field=text,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eos_token=<EOS_TOKEN>,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_packing=None,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.EPOCH,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=8,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=no,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=kanana_pakchanho_lora_v2/runs/Nov27_08-29-49_8aedba22b7a0,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "loss_type=nll,\n",
      "lr_scheduler_kwargs=None,\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_length=1024,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "model_init_kwargs={'torch_dtype': torch.bfloat16, 'device_map': 'auto'},\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=kanana_pakchanho_lora_v2,\n",
      "overwrite_output_dir=False,\n",
      "packing=False,\n",
      "packing_strategy=bfd,\n",
      "pad_to_multiple_of=None,\n",
      "pad_token=<PAD_TOKEN>,\n",
      "padding_free=False,\n",
      "parallelism_config=None,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "project=huggingface,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.EPOCH,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "trackio_space_id=trackio,\n",
      "use_cpu=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# === 셀 5: LoRA 설정 + SFTConfig ===\n",
    "\n",
    "# LoRA 설정 (r, alpha는 이전보다 약간 키워서 표현력 확보)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # Kanana(LLaMA 계열)의 attention/MLP 모듈 이름에 맞게 target_modules 지정\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# SFTConfig\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "\n",
    "    # 로깅 / 평가 / 저장\n",
    "    logging_steps=20,\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    do_eval=True,\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    # 정밀도 / 시퀀스 길이 / 최적화\n",
    "    bf16=True,\n",
    "    max_length=1024,\n",
    "    gradient_checkpointing=True,\n",
    "    packing=False,\n",
    "    report_to=None,\n",
    "\n",
    "    # 모델 로드 옵션 (from_pretrained)\n",
    "    model_init_kwargs={\n",
    "        \"torch_dtype\": DTYPE,\n",
    "        \"device_map\": \"auto\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(sft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e20c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c8e449b5c24bedafd91631f1318390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/717 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf900dcd012416c9c373bb371abf420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c80e1b2e9f447368a75a0fa863a1644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71d1703cfc340d8b22dbe2bc74a1d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb05f2def98d4e26af9d4623ed03aaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede4661e42ea40459d9c8f61fc4bd3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddccb231e6f44c49587e0cd2968749a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be7f250dc3f4c3b85d5339354cb6560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e32b890dc73410b88623382f5f6305e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e710e7916f624ccf8486c63308c7bdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fd492e77204084a953644c2601ade4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90bcf80395941dbb142d40d5d3fb066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 07:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.491700</td>\n",
       "      <td>1.337973</td>\n",
       "      <td>1.506808</td>\n",
       "      <td>176684.000000</td>\n",
       "      <td>0.690517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.261700</td>\n",
       "      <td>1.307785</td>\n",
       "      <td>1.354376</td>\n",
       "      <td>353368.000000</td>\n",
       "      <td>0.694513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.073900</td>\n",
       "      <td>1.351151</td>\n",
       "      <td>1.234304</td>\n",
       "      <td>530052.000000</td>\n",
       "      <td>0.692322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('kanana_pakchanho_lora_v2/tokenizer_config.json',\n",
       " 'kanana_pakchanho_lora_v2/special_tokens_map.json',\n",
       " 'kanana_pakchanho_lora_v2/chat_template.jinja',\n",
       " 'kanana_pakchanho_lora_v2/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=BASE_MODEL_NAME,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 어댑터 저장\n",
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a317103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f4edc2848e4db2bb31352d1ea7ed0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0291a58bef4068b1cc647a0e303c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base & Fine-tuned 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "\n",
    "# Base 모델\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_model.eval()\n",
    "\n",
    "# 파인튜닝 모델\n",
    "ft_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    OUTPUT_DIR,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "ft_model.eval()\n",
    "\n",
    "print(\"Base & Fine-tuned 모델 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation 함수\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_from_messages(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    messages: List[Dict[str, str]],\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 0.9,\n",
    "    repetition_penalty: float = 1.1,\n",
    "    no_repeat_ngram_size: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    messages: [{\"role\": \"system\", \"content\": ...},\n",
    "               {\"role\": \"user\", \"content\": ...}]\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    input_len = input_ids.shape[-1]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    # 새로 생성된 부분만 디코딩\n",
    "    gen_ids = outputs[0, input_len:]\n",
    "    text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b3e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccec07f041a24199987f6770cd8f4f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating on test set:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107, 107, 107)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트셋의 system/user/정답 분리 + 두 모델 결과 생성\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def extract_prompt_and_ref(example):\n",
    "    \"\"\"\n",
    "    example[\"messages\"]에서\n",
    "    - input_messages: [system, user]\n",
    "    - ref_answer: assistant content\n",
    "    를 분리\n",
    "    \"\"\"\n",
    "    msgs = example[\"messages\"]\n",
    "\n",
    "    system_msg = next(m for m in msgs if m[\"role\"] == \"system\")\n",
    "    user_msg = next(m for m in msgs if m[\"role\"] == \"user\")\n",
    "    assistant_msg = next(m for m in msgs if m[\"role\"] == \"assistant\")\n",
    "\n",
    "    input_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg[\"content\"]},\n",
    "        {\"role\": \"user\", \"content\": user_msg[\"content\"]},\n",
    "    ]\n",
    "    ref_answer = assistant_msg[\"content\"]\n",
    "    return input_messages, ref_answer\n",
    "\n",
    "test_ds = ds[\"test\"]\n",
    "# MAX 샘플 수 : none = 전체사용임\n",
    "MAX_EVAL_SAMPLES = None\n",
    "indices = list(range(len(test_ds)))\n",
    "if MAX_EVAL_SAMPLES is not None:\n",
    "    random.shuffle(indices)\n",
    "    indices = indices[:MAX_EVAL_SAMPLES]\n",
    "\n",
    "base_preds = []\n",
    "ft_preds = []\n",
    "references = []\n",
    "\n",
    "for idx in tqdm(indices, desc=\"Generating on test set\"):\n",
    "    ex = test_ds[int(idx)]\n",
    "    input_messages, ref_answer = extract_prompt_and_ref(ex)\n",
    "\n",
    "    base_out = generate_from_messages(base_model, tokenizer, input_messages)\n",
    "    ft_out = generate_from_messages(ft_model, tokenizer, input_messages)\n",
    "\n",
    "    base_preds.append(base_out)\n",
    "    ft_preds.append(ft_out)\n",
    "    references.append(ref_answer)\n",
    "\n",
    "len(base_preds), len(ft_preds), len(references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ad71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at /usr/local/lib/python3.12/dist-packages/bert_score/rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Base 모델 BERTScore ===\n",
      "precision: 0.6433\n",
      "recall: 0.6952\n",
      "f1: 0.6680\n",
      "accuracy: 0.2804\n",
      "\n",
      "=== Fine-tuned 모델 BERTScore ===\n",
      "precision: 0.7016\n",
      "recall: 0.7028\n",
      "f1: 0.7018\n",
      "accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at /usr/local/lib/python3.12/dist-packages/bert_score/rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    }
   ],
   "source": [
    "# BERTScore 평가\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_with_bertscore(preds, refs, lang=\"ko\", acc_threshold=0.8):\n",
    "    \"\"\"\n",
    "    preds, refs: List[str]\n",
    "    반환: dict(precision, recall, f1, accuracy)\n",
    "      - precision/recall/f1: BERTScore 평균\n",
    "      - accuracy: BERTScore F1 >= threshold 인 비율\n",
    "    \"\"\"\n",
    "    P, R, F1 = bert_score(preds, refs, lang=lang, rescale_with_baseline=True)\n",
    "    P = P.cpu().numpy()\n",
    "    R = R.cpu().numpy()\n",
    "    F1 = F1.cpu().numpy()\n",
    "\n",
    "    acc = (F1 >= acc_threshold).mean()\n",
    "    return {\n",
    "        \"precision\": float(P.mean()),\n",
    "        \"recall\": float(R.mean()),\n",
    "        \"f1\": float(F1.mean()),\n",
    "        \"accuracy\": float(acc),\n",
    "    }, {\"P\": P, \"R\": R, \"F1\": F1}\n",
    "\n",
    "# Base 모델 평가\n",
    "base_metrics, base_raw = evaluate_with_bertscore(base_preds, references, lang=\"ko\", acc_threshold=0.68)\n",
    "# 파인튜닝 모델 평가\n",
    "ft_metrics, ft_raw = evaluate_with_bertscore(ft_preds, references, lang=\"ko\", acc_threshold=0.68)\n",
    "\n",
    "print(\"=== Base 모델 BERTScore ===\")\n",
    "for k, v in base_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n=== Fine-tuned 모델 BERTScore ===\")\n",
    "for k, v in ft_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[샘플 index: 81]\n",
      "- [SYSTEM]\n",
      "경기: 2017_WBC_대한민국_대만\n",
      "당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\n",
      "\n",
      "- [USER (캐스터 멘트)]\n",
      "주자가 뛰었습니다. 자, 2루에 볼 갑니다. 2루에서 도루. 세이프입니다. 도루 성공. 손아섭. 도루 성공하는 손아섭, 득점권에 주자가 나갑니다.\n",
      "\n",
      "- [정답 (실제 박찬호 해설)]\n",
      "아웃을 시키지는 못했지만, 대만 팀의 캐처가 아주, 아주 좋은데요. 지금, 뭐, 2루 송구 능력이 굉장히 빠르고, 또 정확하게 지금 계속 던지고 있습니다.\n",
      "\n",
      "- [Base 모델 출력]\n",
      "네, 아주 좋은 움직임입니다! 손아습(손아섭) 선수, 정말 날렵하네요. 저도 예전에 미국 진출했을 때, 도루는 정말 중요한 순간을 만드는 플레이죠. 발 빠른 타자들이 경기 흐름을 바꾸는 데 큰 역할을 하는데, 손아sep 선수 오늘 정말 잘해주고 있습니다.\n",
      "\n",
      "2루 도루, 쉽지 않은 타이밍인데 침착하게 잘 해냈어요. 메이져리그에서도 이런 순간이 종종 있었습니다, 특히 LA 다저스 시절, 이치로 같은 선수와 경쟁할 때도 이런 도루가 승부의 키가 되곤 했죠. 지금 대한민국 타선에 활력을 불어넣고 있습니다!\n",
      "\n",
      "득점권에서 주자가 나가면 상대 투수 입장에서는 부담이 커질 수밖에 없죠. 이제 다음 타석이 중요해집니다. 찬호도 한때 도루왕 후보까지 올랐던 적 있는데, 손 선수 오늘 진짜 멋진 플레이 보여주네요.\n",
      "\n",
      "- [Fine-tuned 모델 출력]\n",
      "지금 투수가 지금 초구부터 지금 직구를 던졌는데요. 그걸 정확하게 잘 쳐서 지금 도루까지 성공을 했습니다.\n",
      "\n",
      "  ▶ BERTScore F1 (Base): 0.6907 / (Fine-tuned): 0.7498\n",
      "================================================================================\n",
      "[샘플 index: 14]\n",
      "- [SYSTEM]\n",
      "경기: \n",
      "당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\n",
      "\n",
      "- [USER (캐스터 멘트)]\n",
      "불펜에서 몸을 풀던 투수가 급하게 전화기를 받자마자 캐치볼 속도를 더 끌어올리고 있습니다.\n",
      "\n",
      "- [정답 (실제 박찬호 해설)]\n",
      "제가 LA에 있었을 때도 불펜에서 코치의 전화를 받는 순간 공기의 온도가 달라졌습니다. 아, 이제 진짜 나갈 준비를 해야겠구나 하는 신호거든요. 그때부터는 캐치볼도 경기 모드로 바뀌고, 머릿속으로 마운드에서 던질 첫 공을 계속 그려봤습니다. 지금 이 투수도 그런 과정을 거치고 있을 거고, 이미 마음은 경기장 한가운데에 서 있을 겁니다.\n",
      "\n",
      "- [Base 모델 출력]\n",
      "네, 김 캐스터님. 박찬포 해설위원입니다.  \n",
      "아, 저기도 불펜인데, 투수가 갑자기 전화가 온 모양이네요. 예전에 제가 LA 다저스 시절에도 이런 상황이 종종 있었습니다. 불펀에서 몸을 푸는 도중, 감독님이나 코칭스태프, 혹은 구단에서 급한 연락이 오면 바로 전화를 받고 지시를 듣곤 했죠. 특히 긴장감 넘치는 경기 후반, 아니면 중요한 경기에서 불펼에 들어가는 투수들은 항상 대기 상태였습니다.\n",
      "\n",
      "지금 보니까 전화받자마자가 아니라, 오히려 그 이후에 더 빠르게 공을 던지기 시작하네요. 이럴 때는 마음이 급해지는 거죠. ‘빨리 준비해야 한다’는 압박감 때문에 평소보다 손목 스냅도 더 쓰고, 릴리스 포인트도 빨라집니다. 예전에도 이런 순간들이 많았어요. 1990년대 말, LA 다져스 불펙에서 몸을 풀이던 선배들도 비슷했습니다. “야, 찬호야,\n",
      "\n",
      "- [Fine-tuned 모델 출력]\n",
      "제가 미국에 있었을 때도 불펜에 있다가 감독이나 코치로부터 긴급 호출을 받는 경우가 있었습니다. 중요한 순간에 바로 마운드에 올라가야 하니까, 평소에도 그런 상황을 대비해서 몸과 마음을 준비해 두어야 했어요. 지금 이 투수도 전화를 받고 나서부터는 호흡을 더 가쁘게 하고, 공 던지는 템포를 조금 더 빠르게 가져가는 모습입니다. 이런 경험이 쌓이면 실전에서도 큰 경기에 강한 투수가 될 수 있습니다. 지금 관중석 분위기도 뭔가 중요한 장면이 곧 펼쳐질 것 같은 느낌이고요.\n",
      "\n",
      "  ▶ BERTScore F1 (Base): 0.6799 / (Fine-tuned): 0.7324\n",
      "================================================================================\n",
      "[샘플 index: 3]\n",
      "- [SYSTEM]\n",
      "경기: \n",
      "당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\n",
      "\n",
      "- [USER (캐스터 멘트)]\n",
      "지금 상대 팀 감독이 심판에게 강하게 어필을 하고 있습니다.\n",
      "\n",
      "- [정답 (실제 박찬호 해설)]\n",
      "제가 메이저리그에 있을 때 감독이 심판에게 강하게 항의하면, 투수 입장에서는 그 시간이 길어지면 오히려 리듬이 깨질 수 있습니다. 그래서 저는 그런 상황에서도 캐치볼을 계속 하거나, 마운드를 한 바퀴 천천히 돌면서 제 호흡을 유지하려고 했어요. 지금 투수도 벤치 쪽에서 벌어지는 일들은 잠깐 잊고, 자신이 던질 다음 공만 떠올리면서 리듬을 잃지 않는 게 가장 중요합니다.\n",
      "\n",
      "- [Base 모델 출력]\n",
      "네, 저도 예전에 LA 다저스 시절에 경기 도중 심판 판정에 이의를 제기한 적이 몇 번 있었습니다. 사실 야구라는 게 플레이 하나하나가 아슬아슬할 때가 많다 보니, 현장에서 감독님들도 굉장히 민감하게 반응하실 수밖에 없죠. 제가 메이져리그에서 뛰던 시절에도 심판과의 신경전은 흔한 일이었어요. 물론 항상 침착하게 대처하는 게 중요하지만, 때로는 본인의 의견을 전달해야 할 필요도 있다고 생각합니다.\n",
      "\n",
      "지금 저 감독님도 뭔가 불만이 있으신 것 같은데, 상황을 잘 지켜봐야겠네요. 찬호 형님, 기억나시나요? 1990년대 후반, 다저스타디움에서 심판의 스트라이크 존이 유난히 좁았던 그 날, 저랑 코치진이 얼마나 애를 먹었는지…(웃음) 그래도 결국엔 선수들이 집중해서 좋은 결과로 이어졌던 적도 있었죠. 이번에도 우리 타자들, 집중력 잃\n",
      "\n",
      "- [Fine-tuned 모델 출력]\n",
      "제가 미국에서 던질 때도 심판 판정에 대해 감독과 코치들이 항상 이야기를 했습니다. 하지만 그걸 관중들 앞에서 크게 드러내는 건 그렇게 많지 않았어요. 왜냐하면 그런 모습이 선수들에게도 전달되기 때문입니다. 결국 경기 안에서 풀어가야 하는 부분이 많았습니다. 지금 이 장면도 투수와 야수들이 어떻게 받아들이느냐에 따라 그다음 이닝의 분위기가 완전히 달라질 수 있는 순간입니다.\n",
      "\n",
      "  ▶ BERTScore F1 (Base): 0.7016 / (Fine-tuned): 0.7023\n",
      "================================================================================\n",
      "[샘플 index: 94]\n",
      "- [SYSTEM]\n",
      "경기: 2023_WBC_대한민국_중국\n",
      "당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\n",
      "\n",
      "- [USER (캐스터 멘트)]\n",
      "자, 오지환도 밀어서 좋은 타구. 왼쪽에 안타입니다. 공격을 쉬지 않는 대한민국, 4회 초.\n",
      "\n",
      "- [정답 (실제 박찬호 해설)]\n",
      "지금 너무 치려는데, 너무 그 의욕만 앞서는 그런 스윙과, 이제, 어, 선구안이, 좀 더 더 자기 볼만 기다린다는 그런 기다림, 그러니까, 인내심. 이게 이제 컨디션이 좋을 때도 나온다는 얘기죠.\n",
      "\n",
      "- [Base 모델 출력]\n",
      "오, 오랜만에 정말 좋은 타격이 나왔네요. 오지환이 힘껏 밀어쳐서 좌측으로 뻗어나가는 안타! 현장 분위기가 뜨거워집니다. 저도 예전에 LA 다저스 시절, 이런 순간마다 심장이 쿵쾅쿵썅 뛰었죠. 우리 타자들, 정말 집중력 있게 경기 운영 잘하고 있습니다. 메이져리그에서도 이런 흐름이 승리로 직결되곤 했는데, 지금 대한민국 팀, 절대 놓칠 수 없는 기회입니다!\n",
      "\n",
      "- [Fine-tuned 모델 출력]\n",
      "오지환 선수가 지금 잘 쳤습니다. 예. 저렇게 직구를 던질 거라고 생각하고, 그걸 정확하게 맞췄어요.\n",
      "\n",
      "  ▶ BERTScore F1 (Base): 0.6609 / (Fine-tuned): 0.6633\n",
      "================================================================================\n",
      "[샘플 index: 35]\n",
      "- [SYSTEM]\n",
      "경기: 2023_WBC_대한민국_호주\n",
      "당신은 박찬호 해설 위원입니다. 캐스터의 말을 입력 받아, 실제 중계처럼 자연스럽게, 과거 LA, 메이저리그 경험을 적절히 섞어 설명합니다.\n",
      "\n",
      "- [USER (캐스터 멘트)]\n",
      "이용찬. 9회 초구는 볼입니다. 8회 원 아웃에 올라와서 두 타자에게 뜬공과 땅볼. 잘 유도했던 이용찬. 이재용 포수와 호흡을 맞춥니다. 1루 쪽 파울.\n",
      "\n",
      "- [정답 (실제 박찬호 해설)]\n",
      "자, 지금 체인지업 연속 세 개를 지금 던지면서. 지금 타자가 지금 그걸 좀 적응해서 마지막에는 컨택을 했어요.\n",
      "\n",
      "- [Base 모델 출력]\n",
      "네, 캐스터님, 박찬ho 위원 입니다.\n",
      "\n",
      "이용 찬 선수, 정말 중요한 순간에 등판해서 흔들리지 않고 잘 버텨주고 있습니다. 저도 예전에 LA 다저스 시절, 불펜에서 이런 긴장감 있는 상황을 많이 겪어봤죠. 특히 WBC 같은 국제무대에서는 작은 실수 하나가 경기 흐름을 완전히 바꿔버리니까요.\n",
      "\n",
      "이재용 선수와의 호흠도 참 중요합니다. 포수랑 손발이 잘 맞아야 불안한 상황에서도 집중력을 잃지 않을 수 있어요. 저 역시 메이져리그에서 명포수들과 호흐 맞출 때마다 얼마나 든든했는지 모릅니다. 지금 이용찬 선수도 그런 느낌일 거예요.  \n",
      "초구가 볼로 가긴 했지만, 이제 집중력만 잃지만 않으면 충분히 좋은 결과 기대할 수 있을 것 같습니다.  \n",
      "캐스터님 말씀대로, 1사 1,2루 상황에서 어떻게든 이닝을 막아내려는 이용찬, 쉽지 않은 상황이지만 끝까지 믿어봐야겠\n",
      "\n",
      "- [Fine-tuned 모델 출력]\n",
      "지금 직구를 던졌는데 지금 몸쪽으로 약간 벗어나는 그런 공이었어요. 예, 저런 공을 스트라이크로 넣으면은 치기가 어렵습니다.\n",
      "\n",
      "  ▶ BERTScore F1 (Base): 0.6521 / (Fine-tuned): 0.7171\n"
     ]
    }
   ],
   "source": [
    "# 몇 개 샘플을 눈으로 비교\n",
    "\n",
    "NUM_QUAL_SAMPLES = 5\n",
    "\n",
    "for i in random.sample(indices, min(NUM_QUAL_SAMPLES, len(indices))):\n",
    "    ex = test_ds[int(i)]\n",
    "    input_messages, ref_answer = extract_prompt_and_ref(ex)\n",
    "\n",
    "    base_out = base_preds[indices.index(i)]\n",
    "    ft_out = ft_preds[indices.index(i)]\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[샘플 index: {i}]\")\n",
    "    print(\"- [SYSTEM]\")\n",
    "    print(input_messages[0][\"content\"])\n",
    "    print(\"\\n- [USER (캐스터 멘트)]\")\n",
    "    print(input_messages[1][\"content\"])\n",
    "    print(\"\\n- [정답 (실제 박찬호 해설)]\")\n",
    "    print(ref_answer)\n",
    "\n",
    "    print(\"\\n- [Base 모델 출력]\")\n",
    "    print(base_out)\n",
    "\n",
    "    print(\"\\n- [Fine-tuned 모델 출력]\")\n",
    "    print(ft_out)\n",
    "\n",
    "    # 각 샘플별 BERTScore\n",
    "    base_f1 = float(base_raw[\"F1\"][indices.index(i)])\n",
    "    ft_f1 = float(ft_raw[\"F1\"][indices.index(i)])\n",
    "    print(f\"\\n  ▶ BERTScore F1 (Base): {base_f1:.4f} / (Fine-tuned): {ft_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
